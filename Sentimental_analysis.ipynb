{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Sentimentale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\nlp\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "from IPython.display import display\n",
    "from transformers  import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reviews = file.readlines()\n",
    "    return reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les titres des films depuis le fichier JSON\n",
    "def load_movie_titles(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        movie_titles = json.load(file)\n",
    "    return movie_titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_reviews(reviews, movie_titles):\n",
    "    total_reviews = 0\n",
    "    for line in reviews:\n",
    "        line = line.strip()  \n",
    "\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"Film : \"):\n",
    "            title = line[len(\"Film : \"):].strip() \n",
    "            if title in movie_titles:\n",
    "                continue \n",
    "        \n",
    "        total_reviews += 1\n",
    "\n",
    "    return total_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de critiques : 750\n"
     ]
    }
   ],
   "source": [
    "file_path = 'critiques_films.txt'  # Chemin vers le fichier de critiques\n",
    "json_file = r'C:\\nlp\\movie_titles.json'  \n",
    "\n",
    "reviews = load_reviews(file_path)\n",
    "movie_titles = load_movie_titles(json_file)\n",
    "s\n",
    "total_reviews = count_reviews(reviews, movie_titles)\n",
    "\n",
    "# Afficher le nombre total de critiques\n",
    "print(f\"Nombre total de critiques : {total_reviews}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de critique nettoyée : on aurait pu sattendre de le part de spielberg à un manichéisme bien politiquement correct on a au contraire une oeuvre sobre dotée dun regard juste et réfléchi sur la nature humaine le réalisateur a réussi à éviter tous les écueils dans lesquels il aurait pourtant été facile de tomber  cest dautant plus admirable emouvant parce que brillant\n",
      "Nombre de critiques nettoyées : 750\n"
     ]
    }
   ],
   "source": [
    "def preprocess_reviews(reviews, movie_titles):\n",
    "    processed_reviews = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        review = review.strip()  # Enlever les espaces au début et à la fin de la ligne\n",
    "\n",
    "        # Si la ligne est vide ou si la ligne est un titre de film, on l'ignore\n",
    "        if not review or review.startswith(\"Film : \"):\n",
    "            continue\n",
    "\n",
    "        # Sinon, on prétraite la critique\n",
    "        review = review.lower()  # Mettre en minuscules\n",
    "        review = re.sub(r'\\d+', '', review)  # Supprimer les chiffres\n",
    "        review = re.sub(r'[^\\w\\s]', '', review)  # Supprimer la ponctuation\n",
    "        processed_reviews.append(review)\n",
    "    \n",
    "    return processed_reviews\n",
    "\n",
    "# Appliquer le prétraitement\n",
    "reviews_cleaned = preprocess_reviews(reviews, movie_titles)\n",
    "print(f\"Exemple de critique nettoyée : {reviews_cleaned[16]}\")\n",
    "print(f\"Nombre de critiques nettoyées : {len(reviews_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critique</th>\n",
       "      <th>film_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>autant javais adoré le premier opus de cette t...</td>\n",
       "      <td>Le Parrain, 2e partie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>star wars  episode v  lempire contreattaque es...</td>\n",
       "      <td>Star Wars : Episode V - L'Empire contre-attaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>cest toujours aussi dingue visuellement le mél...</td>\n",
       "      <td>Spider-Man : Across The Spider-Verse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>trois étoiles peu généreuses ce film est vraim...</td>\n",
       "      <td>Les Temps modernes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>en septembre  dans sa conclusion de son excell...</td>\n",
       "      <td>Dune : DeuxiÃ¨me Partie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>a lheure où bon nombre veulent en découdre con...</td>\n",
       "      <td>Le Comte de Monte-Cristo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>cette trilogie est ma préfèrée les deux tours ...</td>\n",
       "      <td>Le Seigneur des anneaux : les deux tours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>la justice possède sa propre mythologie audelà...</td>\n",
       "      <td>12 hommes en colÃ¨re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>schindlers list ou le meilleur film de steven ...</td>\n",
       "      <td>La Liste de Schindler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>un drame fantastique puissant qui ne peut lais...</td>\n",
       "      <td>La Ligne verte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              critique  \\\n",
       "415  autant javais adoré le premier opus de cette t...   \n",
       "331  star wars  episode v  lempire contreattaque es...   \n",
       "697  cest toujours aussi dingue visuellement le mél...   \n",
       "566  trois étoiles peu généreuses ce film est vraim...   \n",
       "515  en septembre  dans sa conclusion de son excell...   \n",
       "245  a lheure où bon nombre veulent en découdre con...   \n",
       "294  cette trilogie est ma préfèrée les deux tours ...   \n",
       "56   la justice possède sa propre mythologie audelà...   \n",
       "21   schindlers list ou le meilleur film de steven ...   \n",
       "39   un drame fantastique puissant qui ne peut lais...   \n",
       "\n",
       "                                          film_title  \n",
       "415                            Le Parrain, 2e partie  \n",
       "331  Star Wars : Episode V - L'Empire contre-attaque  \n",
       "697             Spider-Man : Across The Spider-Verse  \n",
       "566                               Les Temps modernes  \n",
       "515                          Dune : DeuxiÃ¨me Partie  \n",
       "245                         Le Comte de Monte-Cristo  \n",
       "294         Le Seigneur des anneaux : les deux tours  \n",
       "56                              12 hommes en colÃ¨re  \n",
       "21                             La Liste de Schindler  \n",
       "39                                    La Ligne verte  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('movie_titles.json', 'r') as file:\n",
    "    movie_titles = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "# Créer un DataFrame avec les critiques\n",
    "df = pd.DataFrame({'critique': reviews_cleaned})\n",
    "\n",
    "# Assigner un titre de film à chaque critique. Répartir les 50 titres parmi les 750 critiques.\n",
    "df['film_title'] = [movie_titles[i // (len(reviews_cleaned) // 50)] for i in range(len(reviews_cleaned))]\n",
    "\n",
    "# Vérifier la structure du DataFrame\n",
    "display(df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\nlp\\nlp\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\nlp\\nlp\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing CamembertForSequenceClassification.\n",
      "\n",
      "All the weights of CamembertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CamembertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Modèle déjà fine-tuné pour l'analyse de sentiment en français\n",
    "model_name = \"tblard/tf-allocine\"  # Modèle fine-tuné sur les critiques Allociné !\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, from_tf=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le device (GPU si disponible, sinon CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assurez-vous que le modèle est aussi sur le bon device\n",
    "model = model.to(device)\n",
    "\n",
    "def split_review(review, max_length=512):\n",
    "    # Tokenisation de la critique\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    \n",
    "    # Diviser les tokens en morceaux de taille 'max_length'\n",
    "    chunks = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]\n",
    "    \n",
    "    # Recomposer les morceaux en texte\n",
    "    return [tokenizer.convert_tokens_to_string(chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_for_review(review):\n",
    "    # Diviser la critique en morceaux\n",
    "    chunks = split_review(review)\n",
    "    sentiments = []  # Liste pour stocker les scores de sentiment de chaque chunk\n",
    "    \n",
    "    # Analyser chaque morceau\n",
    "    for chunk in chunks:\n",
    "        # Tokenisation et envoi sur le device (GPU/CPU)\n",
    "        inputs = tokenizer(chunk, truncation=True, padding=True, max_length=512, return_tensors='pt').to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)  # Obtenir les logits du modèle\n",
    "            \n",
    "        # Appliquer softmax pour obtenir les probabilités\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        \n",
    "        # Ajouter le score de sentiment pour ce chunk\n",
    "        sentiment_score = probs[0, 1].item()  # Classe positive (si modèle binaire)\n",
    "        sentiments.append(sentiment_score)\n",
    "    \n",
    "    # Calculer la moyenne des sentiments de tous les chunks\n",
    "    if sentiments:\n",
    "        final_sentiment = sum(sentiments) / len(sentiments)\n",
    "    else:\n",
    "        final_sentiment = 0.5  # Valeur par défaut si pas de chunks\n",
    "        \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['critique'].apply(get_sentiment_for_review)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        film_title  \\\n",
      "20           La Liste de Schindler   \n",
      "431                     Fight Club   \n",
      "311                          Seven   \n",
      "390                       Parasite   \n",
      "184  Le Bon, la brute et le truand   \n",
      "300                          Seven   \n",
      "671             American History X   \n",
      "406          Le Parrain, 2e partie   \n",
      "667             American History X   \n",
      "627         Le Silence des agneaux   \n",
      "\n",
      "                                              critique  sentiment  \n",
      "20   incroyable film sur oskar shindler cet homme n...   0.998835  \n",
      "431  une oeuvre étrange cruelle et violente signée ...   0.997108  \n",
      "311  cest vraiment un excellent thriller  lhistoire...   0.998745  \n",
      "390  le scénario est très bien écrit et beaucoup pl...   0.998492  \n",
      "184  si la trame de fond du bon la bruteet le truan...   0.996877  \n",
      "300  le format et lidée de base sont des plus class...   0.998336  \n",
      "671  aïe plus les années passent et moins je parvie...   0.078688  \n",
      "406  comme son prédecesseur le parrain  ème partie ...   0.998759  \n",
      "667  beaucoup de gens placent american history x en...   0.983343  \n",
      "627  meilleur film meilleur acteur meilleure actric...   0.998769  \n"
     ]
    }
   ],
   "source": [
    "# Voir le DataFrame avec les sentiments\n",
    "print(df[['film_title', 'critique', 'sentiment']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score positif: 0.9985256791114807\n",
      "Score négatif: 0.0008790758438408375\n"
     ]
    }
   ],
   "source": [
    "positive_review = \"Ce film est absolument génial, j'ai adoré!\"\n",
    "negative_review = \"Un des pires films que j'ai vus, ennuyeux et mal joué\"\n",
    "\n",
    "print(f\"Score positif: {get_sentiment_for_review(positive_review)}\")\n",
    "print(f\"Score négatif: {get_sentiment_for_review(negative_review)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               film_title  \\\n",
      "696  Spider-Man : Across The Spider-Verse   \n",
      "701  Spider-Man : Across The Spider-Verse   \n",
      "533  NapolÃ©on vu par Abel Gance partie 2   \n",
      "251              Le Comte de Monte-Cristo   \n",
      "613               Le Tombeau des lucioles   \n",
      "372  NapolÃ©on vu par Abel Gance partie 1   \n",
      "415                 Le Parrain, 2e partie   \n",
      "74                             Le Parrain   \n",
      "640                              Whiplash   \n",
      "624                Le Silence des agneaux   \n",
      "\n",
      "                                              critique  sentiment  \n",
      "696  là où le premier était vraiment une révélation...   0.000664  \n",
      "701  bon je ne vais pas être tendre et je sens que ...   0.000837  \n",
      "533  légèrement inférieure à la première partie ici...   0.001174  \n",
      "251  alors pour ceux qui nont pas lu le livre ou qu...   0.001333  \n",
      "613  la singularité du tombeau des lucioles réside ...   0.001660  \n",
      "372  présenté comme lun des plus grands chefsdœuvre...   0.002223  \n",
      "415  autant javais adoré le premier opus de cette t...   0.004635  \n",
      "74   film élevé au rang de mythe le parrain est de ...   0.005791  \n",
      "640  de la batterie comme instrument de torturepend...   0.008664  \n",
      "624  le silence des agneaux étant considéré comme l...   0.013363  \n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by='sentiment', ascending=True)\n",
    "\n",
    "# Afficher les 10 lignes ayant les moindres sentiments\n",
    "print(df_sorted[['film_title', 'critique', 'sentiment']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation des résumés des critiques des films "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de films: 50\n"
     ]
    }
   ],
   "source": [
    "grouped_reviews = df.groupby('film_title')['critique'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "print(f\"Nombre de films: {len(grouped_reviews)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\nlp\\nlp\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jihed B\\.cache\\huggingface\\hub\\models--facebook--mbart-large-50-many-to-many-mmt. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"  # Modèle français de résumé\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de: cpu\n"
     ]
    }
   ],
   "source": [
    "# 4. Vérifier si GPU est disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"Utilisation de: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.src_lang = \"fr_XX\"  # Français comme langue source\n",
    "tokenizer.tgt_lang = \"fr_XX\"  # Français comme langue cible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_segments(text, max_length=300):  # Réduit à 300 pour CPU\n",
    "    # Diviser par phrases pour une segmentation plus logique\n",
    "    sentences = [s + '.' for s in text.split('.') if s.strip()]\n",
    "    \n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        \n",
    "        sentence_length = len(tokenizer.tokenize(sentence))\n",
    "        if current_length + sentence_length > max_length and current_segment:\n",
    "            # Joindre le segment actuel et le stocker\n",
    "            segments.append(' '.join(current_segment))\n",
    "            current_segment = [sentence]\n",
    "            current_length = sentence_length\n",
    "        else:\n",
    "            current_segment.append(sentence)\n",
    "            current_length += sentence_length\n",
    "    \n",
    "   \n",
    "    if current_segment:\n",
    "        segments.append(' '.join(current_segment))\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text, max_length=100, min_length=30):  #gpu non dispo donc reduit les params \n",
    "    \n",
    "    if len(tokenizer.tokenize(text)) < max_length * 1.2:\n",
    "        return text\n",
    "        \n",
    "    segments = split_text_into_segments(text)\n",
    "    segment_summaries = []\n",
    "    \n",
    "    for segment in segments:\n",
    "        inputs = tokenizer(segment, max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            summary_ids = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_length=max_length,\n",
    "                min_length=min_length,\n",
    "                length_penalty=1.5,\n",
    "                num_beams=2,  \n",
    "                early_stopping=True,\n",
    "                forced_bos_token_id=tokenizer.lang_code_to_id[\"fr_XX\"]  \n",
    "            )\n",
    "            \n",
    "            segment_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            segment_summaries.append(segment_summary)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement d'un segment: {e}\")\n",
    "            # Utiliser une approche de secours en extrayant la première phrase\n",
    "            first_sentence = segment.split('.')[0] + '.'\n",
    "            segment_summaries.append(first_sentence)\n",
    "    \n",
    "    # Joindre tous les résumés des segments\n",
    "    full_summary = ' '.join(segment_summaries)\n",
    "    return full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 50/50 [12:21<00:00, 14.83s/it]\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 50/50 [00:00<00:00, 628.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: 12 hommes en colÃ¨re\n",
      "Mots-clés: ans, ans tous, après, après midi, borré, borré suspense, catégorie, catégorie films\n",
      "Résumé (441 caractères):\n",
      "ans et tous ses dents men en colère fait partie de cette catégorie de films qui, malgré le temps qui passe et les techniques cinématographiques qui change ne perdent pas de leur impact initial tout premier film du regret sidney lumet qui signera par la suite une après-midi de chien serpico le crime de lorient express h ce samedi ce dram psychologique filmé comme un thriller borré de suspense est intense très intelligent et fait douter le\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Film: American History X\n",
      "Mots-clés: amérique, amérique gangrénée, arbore, arbore croix, are, are two, aîné, aîné donner\n",
      "Résumé (359 caractères):\n",
      "Derek et danny are two brothers in the heart dune amérique gangrénée par le racisme le premier arbore une croix gammée sur la poitrine il est violent torturé et prêt à tout pour noyer sa colère le second est larchétype du jeune paumé qui suit le modèle de son frère aîné pour donner sens à sa vie dans la lignée de de gerge orwell ou dorange mécanique de stan\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Film: Coco\n",
      "Mots-clés: après, pixar, acerbe, acerbe contre, annonçant, annonçant mort, ans, ans après\n",
      "Résumé (405 caractères):\n",
      "en après le rachat tout frais de pixar par disney et les sorties concomitantes du doute rebelle et la triste exploitation de la licence planes javais écrit un article acerbe contre le studio à la lampe annonçant même sa mort artistique bon bah voilà qui deux ans après viceversa pixar sort ce coco le film qui démontre à quel point j'étais totalement à côté de la plate moi au sortir de ce film je nai qu'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Film: Django Unchained\n",
      "Mots-clés: spectacle, acteurs, acteurs rendent, avant, avant grand, bravo, bravo contentement, car\n",
      "Résumé (414 caractères):\n",
      "django unchained est avant tout un grand spectacle qui nous fait plein d'œil et quand ce spectacle est pétri de grandes qualités on crie bravo de contentement certes il est sûr que le scénario très simple ne prendra pas la tête et au fond tant mieux car ici tout ce qui compte et loin ce sont les personnages et quels tarentino déroule le tapis rouge à ses acteurs qui lui rendent bien la pareille le duo christoph\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Film: Dune : DeuxiÃ¨me Partie\n",
      "Mots-clés: cest, dune, alors, alors denis, bo, bo magistrale, cast, cast exceptionnel\n",
      "Résumé (449 caractères):\n",
      "que dire chaque plan est éblouissant cest spectaculaire exigeant fin dans l'écriture émouvant inattendu et surprenant mais fidèle au premier dans le rhythm et le style la bo est magistrale et le cast exceptionnel les heures les plus rapides au cinéma depuis longtemps cest incroyable de pouvoir vivre ce genre de saga dans les salles alors que denis villeneuve et son entire team proposent avec dune partie une œuvre cinématographique dune immensité\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "grouped_reviews['summary'] = grouped_reviews['critique'].progress_apply(generate_summary)\n",
    "\n",
    "# 8. Ajouter une fonction pour extraire les mots-clés\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import heapq\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Télécharger les stopwords français si nécessaire\n",
    "try:\n",
    "    french_stopwords = stopwords.words('french')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    french_stopwords = stopwords.words('french')\n",
    "\n",
    "# Ajouter des mots spécifiques aux critiques de films\n",
    "french_stopwords += [\"film\", \"cinéma\", \"voir\", \"bien\", \"très\", \"tout\", \"plus\", \"peut\", \"fait\", \"deux\"]\n",
    "\n",
    "def extract_keywords(text, n=8):\n",
    "    # Utiliser TF-IDF pour extraire les mots-clés\n",
    "    vectorizer = TfidfVectorizer(stop_words=french_stopwords, ngram_range=(1, 2))\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([text])\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Obtenir les scores TF-IDF\n",
    "        scores = tfidf_matrix.sum(axis=0).A1\n",
    "        \n",
    "        # Créer un dictionnaire {mot: score}\n",
    "        word_scores = {feature_names[i]: scores[i] for i in range(len(feature_names))}\n",
    "        \n",
    "        # Extraire les n mots avec les scores les plus élevés\n",
    "        top_keywords = heapq.nlargest(n, word_scores, key=word_scores.get)\n",
    "        return top_keywords\n",
    "    except:\n",
    "        # Fallback simple si TF-IDF échoue\n",
    "        words = [w for w in text.lower().split() if w not in french_stopwords and len(w) > 3]\n",
    "        word_freq = {}\n",
    "        for word in words:\n",
    "            word_freq[word] = word_freq.get(word, 0) + 1\n",
    "        return heapq.nlargest(n, word_freq, key=word_freq.get)\n",
    "\n",
    "# 9. Ajouter des mots-clés pour chaque film\n",
    "grouped_reviews['keywords'] = grouped_reviews['summary'].progress_apply(\n",
    "    lambda x: extract_keywords(x))\n",
    "\n",
    "# 10. Fonction pour afficher les résultats\n",
    "def print_film_summary(film_index):\n",
    "    film = grouped_reviews.iloc[film_index]\n",
    "    print(f\"Film: {film['film_title']}\")\n",
    "    print(f\"Mots-clés: {', '.join(film['keywords'])}\")\n",
    "    print(f\"Résumé ({len(film['summary'])} caractères):\")\n",
    "    print(film['summary'])\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "for i in range(min(5, len(grouped_reviews))):\n",
    "    print_film_summary(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension : Utilisation d'un LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les variables d'environnement du fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# Récupérer la clé API depuis les variables d'environnement\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"La clé API Gemini n'a pas été trouvée dans le fichier .env\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "Tu es un critique de cinéma expert. Voici plusieurs critiques du film \"{film_title}\". \n",
    "\n",
    "Crée un résumé concis (environ 150 mots) qui capture l'essentiel de ces critiques.\n",
    "Mentionne les points forts, les points faibles, et l'impression générale des spectateurs.\n",
    "Identifie 3-5 thèmes ou aspects principaux du film selon ces critiques.\n",
    "\n",
    "Critiques:\n",
    "{critiques}\n",
    "\n",
    "Résumé:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération du résumé pour le film: 12 hommes en colÃ¨re\n",
      "Nombre de critiques: 15\n",
      "\n",
      "Résumé généré:\n",
      "================================================================================\n",
      "\"12 Hommes en colère\" est unanimement salué pour son scénario brillant et ses dialogues percutants, offrant une exploration captivante du système judiciaire et du doute raisonnable. Le huis clos, magistralement mis en scène par Sidney Lumet, renforce la tension palpable et l'atmosphère claustrophobe, immergeant le spectateur au cœur des délibérations.  Les performances des acteurs, notamment Henry Fonda, sont louées pour leur réalisme et leur intensité. \n",
      "\n",
      "Malgré quelques critiques pointant un manque de subtilité et une théâtralité excessive par moments, le film est considéré comme un classique indémodable, pertinent encore aujourd'hui.  Sa conclusion, bien que parfois jugée prévisible, n'enlève rien à la puissance du message.\n",
      "\n",
      "Thèmes principaux:\n",
      "\n",
      "* **Le système judiciaire et ses failles:** Le film explore les faiblesses du système, les préjugés des jurés, et l'importance du doute raisonnable.\n",
      "* **La responsabilité individuelle:**  Chaque juré est confronté à sa propre conscience et à la lourdeur de la décision à prendre.\n",
      "* **La peine de mort:** Le film interroge la légitimité de la peine capitale et les conséquences d'une erreur judiciaire.\n",
      "* **Les préjugés sociaux et le racisme:**  Certains jurés laissent leurs préjugés influencer leur jugement.\n",
      "* **La force de la persuasion et du dialogue:** Un seul homme parvient à remettre en question les certitudes des autres grâce à son argumentation et sa persévérance.\n",
      "================================================================================\n",
      "\n",
      "Le résumé a été sauvegardé dans le fichier 'résumé_12 hommes en colÃ¨re.txt'\n"
     ]
    }
   ],
   "source": [
    "def generate_summary_with_langchain(film_title, critiques_list):\n",
    "    \"\"\"Génère un résumé des critiques d'un film en utilisant LangChain avec Gemini Pro 1.5\"\"\"\n",
    "    \n",
    "    # Joindre les critiques en un seul texte\n",
    "    critiques_text = \"\\n\\n\".join(critiques_list)\n",
    "    \n",
    "    # Créer le message à partir du template\n",
    "    chain = prompt_template | llm\n",
    "    \n",
    "    try:\n",
    "        # Invoquer la chaîne avec les variables\n",
    "        response = chain.invoke({\"film_title\": film_title, \"critiques\": critiques_text})\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la génération du résumé pour {film_title}: {e}\")\n",
    "        return f\"Erreur: {str(e)}\"\n",
    "\n",
    "# Regrouper les critiques par film\n",
    "films = df.groupby('film_title')['critique'].apply(list).reset_index()\n",
    "\n",
    "# Sélectionner un seul film \n",
    "selected_film_index = 0  \n",
    "selected_film = films.iloc[selected_film_index]\n",
    "\n",
    "film_title = selected_film['film_title']\n",
    "critiques = selected_film['critique']\n",
    "\n",
    "print(f\"Génération du résumé pour le film: {film_title}\")\n",
    "print(f\"Nombre de critiques: {len(critiques)}\")\n",
    "\n",
    "# Générer le résumé pour ce film uniquement\n",
    "resume = generate_summary_with_langchain(film_title, critiques)\n",
    "\n",
    "print(\"\\nRésumé généré:\")\n",
    "print(\"=\" * 80)\n",
    "print(resume)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sauvegarder le résultat dans un fichier texte\n",
    "with open(f\"résumé_{film_title.replace(':', '_')}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Film: {film_title}\\n\\n\")\n",
    "    f.write(resume)\n",
    "\n",
    "print(f\"\\nLe résumé a été sauvegardé dans le fichier 'résumé_{film_title.replace(':', '_')}.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
